---
layout: post
title: Medium - Face Detection and Recognition With CoreML and ARKit
description: >
  <a href="https://medium.com/better-programming/face-detection-and-recognition-with-coreml-and-arkit-8b676b7448be">ì›ë¬¸ - Omar Mâ€™Haimdat</a>
author: author

---

Trend íŒŒì•…ì„ Medium ê¸°ê³ ë¬¸ ìš”ì•½ í¬ìŠ¤íŒ… - ARKitì˜ ê¸°ëŠ¥ì„ ì´ìš©í•œ ì–¼êµ´ ê°ì§€ì™€ CoreML ëª¨ë¸ì„ ì´ìš©í•œ ì–¼êµ´ ì¸ì‹ êµ¬í˜„

![500x400](https://miro.medium.com/max/4800/1*mWM2EvPIeMyXiCs149eW3g.png)

## Create a Single View Application

<center>
<img src="https://miro.medium.com/max/4800/1*sSq6SuGzK68mBbmVIsu4Lg.png"/>
</center>
Create a single view app
{:.figure}
ì‹±ê¸€ ë·° ì•±ìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ ì‹œì‘í•´ ë´…ì‹œë‹¤.

ì´ì œ í”„ë¡œì íŠ¸ê°€ ìƒê¸°ì…¨ê² ì£ ? ê·¸ëŸ°ë° ì €ëŠ” ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•±ì€ í”„ë¡œê·¸ë˜ë°ì— ë”°ë¼ì„œ ì™„ì„±ë  ê²ƒì…ë‹ˆë‹¤. í† ê¸€í•˜ê¸° ìœ„í•œ ìŠ¤ìœ„ì¹˜ë‚˜ ë²„íŠ¼ ì—†ì´ ìˆœìˆ˜í•œ ì½”ë“œë§Œ ìˆë‹¤ëŠ” ë§ì´ì£ ğŸ¤—

ì—¬ëŸ¬ë¶„ì€ main.storyboardë¥¼ ì‚­ì œí•˜ê³  AppDelegate.swiftë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•´ ì£¼ì„¸ìš”.

```
func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?) -> Bool {
        // Override point for customization after application launch.
        window = UIWindow(frame: UIScreen.main.bounds)
        window?.makeKeyAndVisible()
        let controller = ViewController()
        window?.rootViewController = controller

        return true
    }
```
deployment infoì— storyboard "Main"ì´ë¼ê³  ì íŒê±¸ ì§€ìš°ì…¨ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.

## Create Your Scene and Add It to the Subview
ì´ ì•±ì—ëŠ” ì•±ì˜ ì‹œì‘ì ì´ ë˜ëŠ” ë·°ì»¨íŠ¸ë¡¤ëŸ¬ í•˜ë‚˜ë§Œ ê°€ì§€ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.

ì´ ë‹¨ê³„ì—ì„œ ìš°ë¦¬ëŠ” ì¹´ë©”ë¼ì˜ ë¼ì´ë¸Œ ì˜ìƒì„ ìë™ì ìœ¼ë¡œ í™”ë©´ ë°°ê²½ì´ ë˜ë„ë¡ í•˜ê¸° ìœ„í•´ì„œ ARKitë¥¼ importí•˜ê³  ARSCNView ì¸ìŠ¤í„´ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ARSCNView ì¸ìŠ¤í„´ìŠ¤ëŠ” ìë™ì ìœ¼ë¡œ SceneKit cameraë¥¼ ì›€ì§ì—¬ì„œ ê¸°ê¸°ì˜ ì‹¤ì œ ì›€ì§ì„ê³¼ ì¼ì¹˜ì‹œí‚µë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” í™”ë©´ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ ë¬¼ì²´ì˜ ì›€ì§ì„ì„ ì¶”ì í•˜ì§€ ì•Šì•„ë„ ë˜ëŠ” ê²ƒì´ì£ .

ì—¬ê¸°ì„œëŠ” ì¹´ë©”ë¼ ì„¸ì…˜ì´ ì „ì²´ í™”ë©´ì„ ì°¨ì§€í•˜ê²Œë” í™”ë©´ ì˜ì—­ì„ ì§€ì •í•´ ì¤ë‹ˆë‹¤.
```
//ARSCNView ì´ˆê¸°í™”
let sceneView = ARSCNView(frame: UIScreen.main.bounds)

```

ViewDidLoad ë©”ì†Œë“œì—ì„œëŠ” ë¸ë¦¬ê²Œì´íŠ¸ë‚˜ í”„ë ˆì„ ë“œëì„ ê°ì‹œí•˜ê¸° ìœ„í•œ í”„ë ˆì„ í†µê³„ ë“±ì„ ì„¤ì •í•©ë‹ˆë‹¤.
```
self.view.addSubview(sceneView) // ARSCNViewë¥¼ ì„œë¸Œë·°ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
sceneView.delegate = self // í•´ë‹¹ ë·°ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ë¸ë¦¬ê²Œì´íŠ¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
sceneView.showsStatistics = true // í†µê³„ë¥¼ í‘œì‹œí•˜ë„ë¡ í•©ë‹ˆë‹¤.
```
## Start an ARFaceTrackingConfiguration session

ARFaceTrackingConfigurationì„ ì‚¬ìš©í•´ì„œ ì„¸ì…˜ì„ ì‹œì‘í•  ê²ƒì…ë‹ˆë‹¤. ì´ ì„¤ì •ì€ iPhone X, Xs, Xrì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ front-facing TrueDepth ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•´ì¤ë‹ˆë‹¤.

ViewDidLoad ë©”ì†Œë“œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
```
override func viewDidLoad() {
        super.viewDidLoad()
        self.view.addSubview(sceneView)
        sceneView.delegate = self
        sceneView.showsStatistics = true
        guard ARFaceTrackingConfiguration.isSupported else { return }
        let configuration = ARFaceTrackingConfiguration()
        configuration.isLightEstimationEnabled = true
        sceneView.session.run(configuration, options: [.resetTracking, .removeExistingAnchors])
    }
```

## Train a Face recognition medel
CoreMLì— ì í•©í•œ .mlmodel íŒŒì¼ì„ ë§Œë“œëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì˜ ë°©ë²•ë“¤ì´ ì¼ë°˜ì ì¸ ì˜ˆ ì…ë‹ˆë‹¤.

1. <b>Turicreate:</b> ê°„ë‹¨í•˜ê²Œ ì»¤ìŠ¤í…€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ê°œë°œí•˜ê¸° ìœ„í•œ íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì…ë‹ˆë‹¤. ë”ìš± ì¤‘ìš”í•œ ê²ƒì€ .mlmodel íŒŒì¼ì„ Xcodeë¡œ íŒŒì‹±í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ì£ .
1. <b>MLImageClassifierBuilder():</b> Xcodeì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” build-in ì†”ë£¨ì…˜ ì´ë©° ë“œë˜ê·¸ ì•¤ ë“œë¡­ ì¸í„°í˜ì´ìŠ¤ë¡œ ê´€ë ¨ëœ ê°„ë‹¨í•œ ëª¨ë¸ì„ í•™ìŠµ ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
<center>
<img src="https://miro.medium.com/max/2000/1*tWDStrIWMHhqcYtj0QJRIg.png"/>
</center>
MLImageClassifierBuilder
{:.figure}

ì €ëŠ” ì¶©ë¶„í•œ ë°ì´í„° ì…‹ì´ ì—†ì—ˆê¸° ë•Œë¬¸ì— ìœ„ì˜ ë‘ ì†”ë£¨ì…˜ì„ ê°€ì§€ê³  í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í–ˆê³  ìµœì¢…ì ìœ¼ë¡œ 67ì¥ì˜ ì €ì˜ ì‚¬ì§„ê³¼ 261ì¥ì˜ ë‹¤ë¥¸ì‚¬ëŒì˜ ì–¼êµ´ ë°ì´í„°ë¥¼ ê°€ì§€ê³  MLImageClassifierBuilderë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤.

í”Œë ˆì´ ê·¸ë¼ìš´ë“œë¥¼ ì¼œì„œ ì•„ë˜ì˜ ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”.
```
import CreateMLUI

let builder = MLImageClassifierBuilder()
builder.showInLiveView()
```

ì €ëŠ” ìµœëŒ€ iterationsë¥¼ 20ìœ¼ë¡œ ì„¤ì •í•˜ì‹œê³  ê° ì´ë¯¸ì§€ë§ˆë‹¤ í¬ë¡­ëœ 4ì¥ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¶”ê°€í•´ì£¼ëŠ” í¬ë¡­ ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì‹œê¸¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.

## Capture Camera Frames and Inject Them Into the model
ìš°ë¦¬ì˜ ë·°ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ scene delegateë¥¼ ì‚¬ìš©í•´ í™•ì¥í•´ì•¼ í•©ë‹ˆë‹¤. 2ê°œì˜ ë¸ë¦¬ê²Œì´íŠ¸ ë©”ì†Œë“œê°€ í•„ìš”í•œë° í•˜ë‚˜ëŠ” ì–¼êµ´ì„ ê°ì§€í•˜ëŠ” ê²ƒì´ê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì–¼êµ´ì´ ê°ì§€ ë˜ì—ˆì„ ë•Œ í™”ë©´ì„ ì—…ë°ì´íŠ¸ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

### Face detection:
```
func renderer(_ renderer: SCNSceneRenderer, nodeFor anchor: ARAnchor) -> SCNNode? {

        guard let device = sceneView.device else {
            return nil
        }

        let faceGeometry = ARSCNFaceGeometry(device: device)

        let node = SCNNode(geometry: faceGeometry)

        node.geometry?.firstMaterial?.fillMode = .lines

        return node
    }
```

ë¶ˆí–‰í•˜ê²Œë„ ì œê°€ ëˆˆì´ë‚˜ ì…ì„ ì—´ì–´ë„ í™”ë©´ì´ ì—…ë°ì´íŠ¸ ë˜ì§€ ì•Šë”ë¼êµ¬ìš”, ì´ëŸ´ ë•ŒëŠ” ì½”ë“œë¥¼ ì´ìš©í•´ì„œ ì—…ë°ì´íŠ¸ë¥¼ í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.
### Update the scene:

```
func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {

        guard let faceAnchor = anchor as? ARFaceAnchor,
            let faceGeometry = node.geometry as? ARSCNFaceGeometry else {
                return
        }

        faceGeometry.update(from: faceAnchor.geometry)
}
```
ìš°ë¦¬ëŠ” ì–¼êµ´ ì „ì²´ë¥¼ ë„í˜•ìœ¼ë¡œ ë§¤í•‘í–ˆê³  ê·¸ ë…¸ë“œë¥¼ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤.

### Get the camera frames:
ARSCNViewê°€ AVCaptrueSessionìœ¼ë¡œ ë¶€í„° ìƒì†ë˜ê¸° ë•Œë¬¸ì— ìš°ë¦¬ëŠ” cvPixelBufferë¥¼ ì‚¬ìš©í•´ì„œ ìš°ë¦¬ì˜ ëª¨ë¸ì— ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì•„ë˜ëŠ” sceneViewì—ì„œ í”½ì…€ ë²„í¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì‰¬ìš´ ë°©ë²• ì…ë‹ˆë‹¤.
```
guard let pixelBuffer = self.sceneView.session.currentFrame?.capturedImage else { return }
```

### Inject camera frames into the model:
ì´ì œ ìš°ë¦¬ëŠ” ì–¼êµ´ì„ ê°ì§€í•˜ê³  ë§¤ ì¹´ë©”ë¼ í”„ë ˆì„ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ì œ ëª¨ë¸ì—ê²Œ ì»¨í…íŠ¸ë¥¼ í”¼ë“œí•  ì¤€ë¹„ê°€ ë˜ì—ˆêµ°ìš”.
```
guard let model = try? VNCoreMLModel(for: FaceRecognition3().model) else {
            fatalError("Unable to load model")
        }

        let coreMlRequest = VNCoreMLRequest(model: model) {[weak self] request, error in
            guard let results = request.results as? [VNClassificationObservation],
                let topResult = results.first
                else {
                    fatalError("Unexpected results")
            }

            DispatchQueue.main.async {[weak self] in
                print(topResult.identifier)
            }
        }

        guard let pixelBuffer = self.sceneView.session.currentFrame?.capturedImage else { return }


        let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:])
        DispatchQueue.global().async {
            do {
                try handler.perform([coreMlRequest])
            } catch {
                print(error)
            }
        }
```
## Show the Name Above the Recognized face
ì¡°ê¸ˆ ì‹¤ë§ìŠ¤ëŸ¬ìš¸ ìˆ˜ë„ ìˆëŠ” ë§ˆì§€ë§‰ íŒŒíŠ¸ëŠ” ì¸ì‹ëœ ì–¼êµ´ ìœ„ì— 3D í…ìŠ¤íŠ¸ë¥¼ ë„ìš°ëŠ” ê²ƒì…ë‹ˆë‹¤. ìƒê°í•´ë³´ì‹œë©´ ì•Œê² ì§€ë§Œ ìš°ë¦¬ê°€ í•œ ì„¤ì •ì€ ARWorldTrackingConfiguration ì²˜ëŸ¼ ë§ì€ ë©”ì†Œë“œì™€ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ê²ƒì´ ì•„ë‹™ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì „ë©´ ì¹´ë©”ë¼ë¥¼ ì´ìš©í•´ì„œ ì•„ì£¼ ì¼ë¶€ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆì£ .

ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ìš°ë¦¬ëŠ” 3D í…ìŠ¤íŠ¸ë¥¼ í™”ë©´ì— ë„ìš¸ê²ë‹ˆë‹¤, ì•„ë§ˆ ì–¼êµ´ ì›€ì§ì„ì„ ë”°ë¼ì„œ ì ì ˆí•˜ê²Œ ì›€ì§ì´ì§„ ì•Šê² ì§€ë§Œìš”.

```
let text = SCNText(string: "", extrusionDepth: 2)
let font = UIFont(name: "Avenir-Heavy", size: 18)
text.font = font
let material = SCNMaterial()
material.diffuse.contents = UIColor.black
text.materials = [material]
text.firstMaterial?.isDoubleSided = true

let textNode = SCNNode(geometry: faceGeometry)
textNode.position = SCNVector3(-0.1, -0.01, -0.5)
textNode.scale = SCNVector3(0.002, 0.002, 0.002)
textNode.geometry = text
```

ì´ì œ ìš°ë¦¬ëŠ” SCNText objectê°€ ìƒê²¼ìŠµë‹ˆë‹¤. ì¼ì¹˜í•˜ëŠ” ì–¼êµ´ì„ ê°€ì§€ê³  ì—…ë°ì´íŠ¸ë¥¼ í•´ì„œ rootNode:ì— ì¶”ê°€í•©ì‹œë‹¤.
```
let coreMlRequest = VNCoreMLRequest(model: model) {[weak self] request, error in
            guard let results = request.results as? [VNClassificationObservation],
                let topResult = results.first
                else {
                    fatalError("Unexpected results")
            }

            DispatchQueue.main.async {[weak self] in
                print(topResult.identifier)
                if topResult.identifier != "Unknown" {
                    text.string = topResult.identifier
                    self!.sceneView.scene.rootNode.addChildNode(textNode)
                    self!.sceneView.autoenablesDefaultLighting = true
                }
            }
        }
```
## Final Result:
ì•„ë˜ì˜ ì´ë¯¸ì§€ëŠ” ì–¼êµ´ ê°ì§€ì™€ ì¸ì‹ì— ëŒ€í•œ ìµœì¢… ê²°ê³¼ë¬¼ ì…ë‹ˆë‹¤.

![500x400](https://miro.medium.com/max/1200/1*bVGRNGkBNVndmGgwyScqWg.gif)

<b>Github Project</b> - <a href="https://github.com/omarmhaimdat/WhoAreYou?source=post_page---------------------------">omarmhaimdat/WhoAreYou</a>

## Summary
* iPhone X, Xs, Xrì˜ ì „ë©´ ì¹´ë©”ë¼ì˜ ì–¼êµ´ ì¶”ì ê¸°ëŠ¥ì„ ì´ìš©í•˜ì—¬ ì–¼êµ´ì„ ë„í˜•ìœ¼ë¡œ ë§µí•‘í•˜ê³  ëª¨ë¸ì—ê²Œ í•´ë‹¹ ì •ë³´ë¥¼ í”¼ë“œí•  ìˆ˜ ìˆìŒ
* íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ì„œ CoreMLì„ í†µí•´ ëª¨ë¸ì—ê²Œ í•™ìŠµì„ ì‹œí‚¬ ìˆ˜ ìˆìŒ
* ì–¼êµ´ ì¶”ì  ê¸°ëŠ¥ì„ ì´ìš©í•´ ì–¼êµ´ ì •ë³´ë¥¼ ë§µí•‘í•˜ê³  ë¨¸ì‹ ëŸ¬ë‹ì„ í†µí•´ ì–¼êµ´ ì¸ì‹ì„ í•™ìŠµì‹œí‚¤ëŠ” ê°„ë‹¨í•œ ì•±
