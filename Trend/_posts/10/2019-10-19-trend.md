---
layout: post
title: Medium - Google’s A.I.-Powered Camera Was Destined to Fail
description: >
  <a href="https://onezero.medium.com/googles-a-i-powered-camera-was-destined-to-fail-101810fbc434">원문 - Dave Gershgorn</a>
author: author
comments: true
---
Trend 파악을 Medium 기고문 요약 포스팅 - 구글의 AI 기반 카메라가 실패로 끝이나다; 프로그램이 무엇이 흥미로운지 구분하지 못했습니다.

<center>
<img src="https://miro.medium.com/max/10756/1*FBjGws2L_mPCUtOR_7QH1Q.jpeg"/>
</center>
Credit: The Washington Post/Getty Images
{:.figure}

구글은 Clips camera의 마개를 닫았습니다. 해당 카메라는 작은 장치로서 일상에 놓칠 수 있는 사진들을 기록하는데 사용되었습니다. 아마 사진들은 여러분의 자녀들이 미소짓는 모습이나 강아지가 문앞에서 꼬리를 흔드는 모습이었겠죠. 그러나 리뷰어와 소비자들이 해당 장치를 사용했을 때 그런 동화같은 일은 일어나지 않았습니다.

"저는 카메라를 셔츠에 장착하고 7살배기 딸이랑 놀 때 그녀석의 미소를 담았으면 하는 바램을 가지고 있었습니다. 앱에 로그인 했을 때는 아무것도 없었고 전 그 카메라를 박살내버렸죠". Best Buy의 리뷰어의 평입니다.

구글은 AI를 사용해서 여러분의 삶에 흥미로운 순간들을 찍을 것이라고 약속했습니다만 그것이 정확히 문제가 되는 부분이었습니다. "interesting"에 대한 정의가 없었던 것입니다.

사용자로서 여러분은 어떤 사진을 찍고싶은지 구글에게 많은 시간을 들여 보여줘야합니다. Endgadget의 Cherlynn Low는 그녀가 작년에 Clips의 AI를 그녀의 일상을 담은 시각적인 레퍼런스로 구글 포토 라이브러리를 사용해 학습시켰지만 아직도 그녀의 개나 친구와 같은 괜찮은 사진을 얻지 못하고 있다고 썼습니다.

우리가 알고있는 AI가 잘하는 것은 이런 것입니다; 명핵하게 올바른 대답을 결정하는 것이죠. 이미지에 개가 있다면 구글은 그것을 식별해 낼수 있습니다. 강아지는 실제거든요. 그러나 강아지가 쓰레기를 뒤지다가 죄지은 표정을 짓는 것처럼이 여러분이 다시 보고싶은 사진을 구글이 인식하게 하려면 모든 유저가 똑같지 않은 엄청난 외부 정보가 필요할 것입니다.

한마디로 AI는 어떤 것의 질을 측정하는 것에는 동작하지 않는 것입니다. 이것은 사람이 어떤 사진이 좋고 나쁜지 판가름하는 것에 확장할 수 있습니다.

> 기본적으로 우리는 두살배기에게 영어를 가르칠 때 "가다, 강아지, 가다"라고 교육한게 아니라 셰익스피어의 작품을 읽어준 셈이죠.

구글의 원래 희망은 해당 AI에 전문가의 사진들을 합슥시켜서 카메라가 구도와 구성과 같은 장점들이 잘 나타나게 사진을 찍는 것을 바랬습니다. 그러나 2018년 <a href="https://design.google/library/ux-ai/">구글의 포스트</a>에 따르면 해당 목적은 달성하기에 너무 모호했죠.

Clips의 UX 디자이너 Josh Lovejoy는 이렇게 썼습니다. "해당 분야의 깊이에 대해서 너무 낭만적으로 얘기를 했습니다. 드라마틱한 조명, 딱 맞는 구도, 스토리텔링 등.. 그러나 제가 배운 것은 우리는 절대로 상식에 영향을 미치는 인간의 능력을 과소평가하면 안된다는 것입니다.", "기본적으로 우리는 두살배기한테 영어를 가르칠 때 쉬운 단어가 아니라 셰익스피어의 작품을 읽어준 것입니다"

대신에 디자이너들은 초점이 맞지 않거나 화이트밸런스가 맞지 않는 것 처럼 카메라가 할 수 있는 더욱 일반적인 실수를 식별했고 그런 최악의 결과물이 덜 나오도록 카메라를 최적화 시키는 노력을 했습니다. 해당 작업은 사용자의 몫이 되었습니다. Clips는 사용자에게 카메라로 찍힌 좋은 사진을 선택하길 요청해서 어떤 사진이 올바른 사진인지 AI를 학습할 수 있도록 사용자에게 요청했습니다. 하지만 여전히 카메라가 왜 그 사진이 좋은지는 알지못하죠. 사진을 스스로 찍는 것 대신에 카메라를 학습시켜서 다음에 좋은 사진을 찍을 수 있도록 하는 것이죠. 불확실한 결과를 바라면서 시간을 투자하는 셈입니다. 이미 기계값으로 250달러나 지불하고 말이죠.

Clips의 제작자는 이러한 기기의 단점을 인정했습니다

Lovejoy는 다음과 같이 말했습니다. "주관적이고 개인화의 맥락에서 완벽함은 간단히 불가능하고 목표가 되어선 안됩니다. 다른 소프트웨어 개발과 달리 ML 시스템은 예측한다는 것이 선천적으로 fuzzy science이기 때문에 버그가 없을 수 없기 때문입니다."

## Summary
* 구글의 AI 기반 카메라 Clips의 실패이유
* 사람들이 원하는 순간을 AI로 학습시키는 것에는 많은 데이터가 필요하다.
* ML 모델은 정확한 답을 찾아내는 것이 아닌 주관적이고 개인적인 답을 고르는 데는 적합하지 않다.
* 포커스나 화이트밸런스를 카메라가 최적화 해주는 것도 사용자가 사진을 선택해서 최적화 시켜야 하기 때문에 Clips는 성공적인 제품이 되지 못했다. 그냥 사진을 찍는 거보다 더 불편하니까
